{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "from scipy.stats import zscore as z_transform\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, render=False):\n",
    "    \n",
    "    all_obs = []\n",
    "    all_ac = []\n",
    "    rw = 0\n",
    "    observation = env.reset()\n",
    "    \n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        # get the distribution over action space from the model\n",
    "        action_dist = model.predict(\n",
    "            tf.expand_dims(tf.convert_to_tensor(observation, tf.float32), axis=0)\n",
    "        )[0]\n",
    "        \n",
    "        # choose the highest value to simplify things\n",
    "        # alternatively, could sample from action space:\n",
    "        # action = int(np.random.choice(np.arange(2), p=action_dist))\n",
    "        action = tf.argmax(action_dist).numpy()\n",
    "        # get the information about the state of the system following the action\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        all_obs.append(observation)\n",
    "        all_ac.append(action)\n",
    "        rw += reward\n",
    "        # done specifies that the session is over, usually due to a win or loss\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    # return the observations and rewards (the reward will be discounted later)\n",
    "    return all_obs, rw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the model architecture\n",
    "# a simple model suffices for such a low dimension, low complexity case\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(env.observation_space.shape)),\n",
    "    # constrain the weights to avoid growth without bound\n",
    "    tf.keras.layers.Dense(64), \n",
    "    tf.keras.layers.Dense(64), \n",
    "                          #kernel_constraint=tf.keras.constraints.unit_norm(),\n",
    "                          #bias_constraint=tf.keras.constraints.unit_norm()),\n",
    "        tf.keras.layers.Dense(env.action_space.n, \n",
    "                              #kernel_constraint=tf.keras.constraints.unit_norm(),\n",
    "                              #bias_constraint=tf.keras.constraints.unit_norm(),\n",
    "                              activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discount rewards so that actions close to the end of the game have a larger weight\n",
    "# a larger gamma makes early actions matter more\n",
    "def discount(rw, gamma=0.9):\n",
    "    weights = np.array([gamma**(rw.shape[0]-i-1) for i in range(rw.shape[0])])\n",
    "    discounted = tf.convert_to_tensor(weights, dtype=tf.float32) * rw\n",
    "    return discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strengthen the outputs based on the size of the reward\n",
    "# this reinforces all decisions, but the unit norm constraint compensates for the growing weights\n",
    "# also, rewards are batch-normalized, such that the worst performance gets a negative reward and the best a positive one\n",
    "def compute_loss(model, obs, rw):\n",
    "    y_pred = model(obs)\n",
    "    y_true = tf.round(y_pred)\n",
    "    #return tf.reduce_sum((y_pred - y_true) ** 2) * rw\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred) * rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(model, optimizer, batch_size, show=False):\n",
    "    \n",
    "    obs_list = []\n",
    "    rw_list = []\n",
    "    l = 0\n",
    "    \n",
    "    for _ in range(batch_size):\n",
    "        obs, rw = run(model, show)\n",
    "        obs_list.append(obs)\n",
    "        rw_list.append(rw)\n",
    "    \n",
    "    print('rewards: ', rw_list)\n",
    "    # normalize rewards\n",
    "    rw_norm = z_transform(np.array(rw_list))\n",
    "    # convert to tensors to discount\n",
    "    rw_tensors = [tf.ones(shape=len(obs_list[i])) * rw for i, rw in enumerate(rw_norm)]\n",
    "    rw_discount = [discount(rw) for rw in rw_tensors]\n",
    "    obs_tensors = [tf.convert_to_tensor(obs, dtype=tf.float32) for obs in obs_list]\n",
    "    \n",
    "    gradients = []\n",
    "    \n",
    "    # for each set of observations and discounted rewards\n",
    "    for obs, rw in zip(obs_tensors, rw_discount):\n",
    "        # and for each frame in the simulation, which has one associated reward\n",
    "        for i in range(tf.shape(obs)[1]):\n",
    "            obs_tens = tf.expand_dims(tf.convert_to_tensor(obs.numpy()[i, :], tf.float32), axis=0)\n",
    "            # calculate the gradient with respect to that one instance\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = compute_loss(model, obs_tens, rw[i])\n",
    "                loss = tf.convert_to_tensor(loss, dtype=tf.float32)\n",
    "            g = tape.gradient(loss, model.trainable_variables)\n",
    "            # collect all the gradients, instead of applying them at each step which would give inaccurate rewards\n",
    "            gradients.append(g)\n",
    "        avg_gradients = []\n",
    "    \n",
    "    # each k represents a kernel's gradients\n",
    "    for k in range(len(gradients[0])):\n",
    "        # get all of the gradients associated to one kernel\n",
    "        t = tf.convert_to_tensor([grad[k] for grad in gradients])\n",
    "        t = tf.reduce_sum(t, axis=0)\n",
    "        avg_gradients.append(t)\n",
    "    \n",
    "    assert not np.isnan(avg_gradients[0][0][0])\n",
    "    # apply the gradients to their respective variables\n",
    "    optimizer.apply_gradients(zip(avg_gradients, model.trainable_variables))\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  [-200.0, -200.0, -200.0, -200.0, -200.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shawn.laptop-ba3eqtsr\\python\\tensor\\lib\\site-packages\\scipy\\stats\\stats.py:2315: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fd6161beddc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-e7362ba32162>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(model, optimizer, batch_size, show)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mavg_gradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_gradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;31m# apply the gradients to their respective variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training is much faster if we don't show the simulation. But thats all the fun!\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    batch_train(model, optimizer, 5, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
